{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a92000-7b82-44c0-8376-1ce30b67c9ba",
   "metadata": {},
   "source": [
    "# Fetch data\n",
    "\n",
    "Dataset created by Maas et al. (2011), available [here](https://ai.stanford.edu/~amaas/data/sentiment/])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68687f9f-dfc5-45ba-9bbc-9758e4b6e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c9628-94cc-4e83-9cc4-71169522566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/processed/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfa4b8-30c2-47ad-bf3e-9901d08e66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "def get_data():\n",
    "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    filename = \"aclImdb_v1.tar.gz\"\n",
    "    \n",
    "    print(\"Downloading file...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(filename, 'wb') as file, tqdm(\n",
    "            desc=filename,\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "    \n",
    "    print(\"Extracting file...\")\n",
    "    if os.path.exists(\"aclImdb\"):\n",
    "        shutil.rmtree(\"aclImdb\")\n",
    "    with tarfile.open(filename) as tar:\n",
    "        tar.extractall(filter='data')\n",
    "\n",
    "    print(\"Renaming folder...\")\n",
    "    if os.path.exists(\"data/raw\"): \n",
    "        shutil.rmtree(\"data/raw\")\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    os.rename(\"aclImdb\", \"data/raw\")\n",
    "    \n",
    "    print(\"Cleaning up...\")\n",
    "    os.remove(filename)\n",
    "    \n",
    "    print(\"Done! The dataset is now available in the 'data/raw' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fb1fe-5d18-4dd7-860a-fb3026a084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure\n",
    "def process_data(base_dir):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    unsup_data = []\n",
    "    \n",
    "    # Process both train and test splits\n",
    "    for split in ['train', 'test']:\n",
    "        split_path = os.path.join(base_dir, split)\n",
    "            \n",
    "        # Process positive and negative reviews\n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            sentiment_path = os.path.join(split_path, sentiment)\n",
    "            sentiment_label = 'positive' if sentiment == 'pos' else 'negative'\n",
    "            \n",
    "            # Skip if directory doesn't exist\n",
    "            if not os.path.exists(sentiment_path):\n",
    "                print(f\"Warning: {sentiment_path} does not exist\")\n",
    "                continue\n",
    "                \n",
    "            # Find all text files\n",
    "            files = glob.glob(os.path.join(sentiment_path, '*.txt'))\n",
    "            \n",
    "            for file_path in files:\n",
    "                # Extract id and rating from filename\n",
    "                filename = os.path.basename(file_path)\n",
    "                match = re.match(r'(\\d+)_(\\d+)\\.txt', filename)\n",
    "                \n",
    "                if match:\n",
    "                    review_id, rating = match.groups()\n",
    "                    \n",
    "                    # Read the review text\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                        text = f.read().strip()\n",
    "                    \n",
    "                    # Add to appropriate list based on split\n",
    "                    entry = {\n",
    "                        'id': int(review_id),\n",
    "                        'text': text,\n",
    "                        'sentiment': sentiment_label,\n",
    "                        'rating': int(rating)\n",
    "                    }\n",
    "                    \n",
    "                    if split == 'train':\n",
    "                        train_data.append(entry)\n",
    "                    else:\n",
    "                        test_data.append(entry)\n",
    "        \n",
    "        # Process unsupervised data in train split\n",
    "        if split == 'train':\n",
    "            unsup_path = os.path.join(split_path, 'unsup')\n",
    "            files = glob.glob(os.path.join(unsup_path, '*.txt'))\n",
    "                \n",
    "            for file_path in files:\n",
    "                # Extract id from filename\n",
    "                filename = os.path.basename(file_path)\n",
    "                match = re.match(r'(\\d+)_0\\.txt', filename)\n",
    "                    \n",
    "                if match:\n",
    "                    review_id = match.groups()[0]\n",
    "                        \n",
    "                    # Read the review text\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                        text = f.read().strip()\n",
    "                        \n",
    "                    # Add to unsupervised data list\n",
    "                    unsup_data.append({\n",
    "                        'id': int(review_id),\n",
    "                        'text': text\n",
    "                    })\n",
    "    \n",
    "    # Convert lists to DataFrames\n",
    "    train = pd.DataFrame(train_data)\n",
    "    test = pd.DataFrame(test_data)\n",
    "    unsup = pd.DataFrame(unsup_data)\n",
    "    \n",
    "    return train, test, unsup\n",
    "\n",
    "train, test, unsup = process_data(\"data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a06aa9-f230-4d4f-b496-392ce08f3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that data is correctly loaded\n",
    "print(f\"Train data shape: {train.shape}\")\n",
    "print(f\"Test data shape: {test.shape}\")\n",
    "print(f\"Unsupervised data shape: {unsup.shape}\")\n",
    "\n",
    "print(\"\\nTrain data:\")\n",
    "print(train.head(2))\n",
    "print(\"\\n\")\n",
    "print(\"\\nTest data sample:\")\n",
    "print(test.head(2))\n",
    "print(\"\\n\")\n",
    "print(\"\\nUnsupervised data sample:\")\n",
    "print(unsup.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc907150-1f74-48b4-9c15-25df4e876eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id column as movie_id to avoid confusion\n",
    "train = train.rename(columns={'id': 'movie_id'})\n",
    "test = test.rename(columns={'id': 'movie_id'})\n",
    "\n",
    "# Create reviews id for matching with the original dataset\n",
    "train['review_id'] = train.index + 1\n",
    "test['review_id'] = test.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1bab4f-be84-453d-a492-745dcb509932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "train.to_csv(\"data/processed/train.csv\", index=False)\n",
    "test.to_csv(\"data/processed/test.csv\", index=False)\n",
    "unsup.to_csv(\"data/processed/unsup.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
