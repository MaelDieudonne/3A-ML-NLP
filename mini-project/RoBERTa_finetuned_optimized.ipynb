{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08144275-905a-4829-836f-517d8294e17f",
   "metadata": {},
   "source": [
    "# Fine-tuning RoBERTa - efficient approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68687f9f-dfc5-45ba-9bbc-9758e4b6e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enlighten\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2ecc8-6384-471b-964d-f1a536724bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): device = torch.device(\"mps\")\n",
    "else: device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551f14c-1c9a-422b-97fe-a915300b0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/embeddings/\", exist_ok=True)\n",
    "os.makedirs(\"output/preds/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283350c-522b-4206-b01e-40fb59ad359a",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To improve efficiency, perform a forward pass through the base model, and store the resulting embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21a646-a7df-4b8c-9796-958d61a9cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, tokenizer, base_model, label2id, batch_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.base_model = base_model.to(device)\n",
    "        self.base_model.eval()\n",
    "        self.label2id = label2id\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def extract_embeddings(self, texts):\n",
    "        \"\"\"Parallelized embedding extraction in batches with progress bar.\"\"\"\n",
    "        dataloader = DataLoader(texts, batch_size=self.batch_size, shuffle=False)\n",
    "        all_embeddings = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"Extracting Embeddings\", leave=True):\n",
    "                tokens = self.tokenizer(\n",
    "                    batch,\n",
    "                    padding=\"longest\",\n",
    "                    truncation=True,\n",
    "                    return_token_type_ids=False,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(device)\n",
    "\n",
    "                outputs = self.base_model(**tokens)\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "                all_embeddings.append(embeddings.cpu())          # Move to CPU to save memory\n",
    "\n",
    "        return torch.cat(all_embeddings, dim=0)  # Concatenate all batches\n",
    "\n",
    "    def prepare(self, data):\n",
    "        \"\"\"Prepare dataloader with precomputed embeddings.\"\"\"\n",
    "        texts = data[\"text\"].tolist()\n",
    "        embeddings = self.extract_embeddings(texts)\n",
    "\n",
    "        # Convert labels\n",
    "        numeric_labels = [self.label2id[label] for label in data[\"sentiment\"]]\n",
    "        labels = torch.tensor(numeric_labels, dtype=torch.long)\n",
    "\n",
    "        # Extract review IDs\n",
    "        ids = torch.tensor(data[\"review_id\"].tolist(), dtype=torch.long)\n",
    "\n",
    "        # Create dataset and dataloader\n",
    "        dataset = TensorDataset(embeddings, labels, ids)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585092f9-3d63-4b57-88f1-f7041bdf9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
    "base_model = RobertaModel.from_pretrained(\"roberta-large\")\n",
    "\n",
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "label2id = {\"negative\": 0, \"positive\": 1}\n",
    "\n",
    "batch_size = 250\n",
    "\n",
    "preprocessor = DataPreprocessor(tokenizer, base_model, label2id, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de8060-2d92-4f29-8aca-01251f2c2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_savefile = \"data/embeddings/train.pt\"\n",
    "\n",
    "if os.path.exists(train_savefile):\n",
    "    print(f\"Loading embeddings for train samples\")\n",
    "    train_tensors = torch.load(train_savefile)\n",
    "    train_dataset = TensorDataset(*train_tensors)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    train = pd.read_csv(\"data/processed/train.csv\")\n",
    "    train_dataloader = preprocessor.prepare(train)\n",
    "    train_dataset = train_dataloader.dataset\n",
    "    torch.save(train_dataset.tensors, train_savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8679b1-19f2-4519-87af-bebd28a77825",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_savefile = \"data/embeddings/test.pt\"\n",
    "\n",
    "if os.path.exists(test_savefile):\n",
    "    print(f\"Loading embeddings for validation samples\")\n",
    "    test_tensors = torch.load(test_savefile)\n",
    "    test_dataset = TensorDataset(*test_tensors)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=250, shuffle=True)\n",
    "else:\n",
    "    test = pd.read_csv(\"data/processed/test.csv\")\n",
    "    test_dataloader = preprocessor.prepare(test)\n",
    "    test_dataset = test_dataloader.dataset\n",
    "    torch.save(test_dataset.tensors, test_savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026af54-5eb7-476f-a24b-71f797716049",
   "metadata": {},
   "source": [
    "# Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc7228-4195-481b-a2ef-cf77cb134a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaClassifier(nn.Module): \n",
    "    def __init__(self, embedding_dim=1024, mod=1): \n",
    "        super(RoBERTaClassifier, self).__init__()\n",
    "      ### Parameters\n",
    "        self.mod = mod\n",
    "        self.hidden_size = 1024 if mod == 1 else 2048\n",
    "        self.inter_size = 1024 if mod == 1 else 512\n",
    "      ### Layers\n",
    "      ### Must be activated in __init__ for the trainable parameters count to be exact\n",
    "        self.in_proj = nn.Linear(embedding_dim, self.hidden_size)           # Input layer\n",
    "        self.dropout = nn.Dropout(0.1)                                      # Dropout layer\n",
    "        self.silu = nn.SiLU()                                               # Activation\n",
    "        if mod >= 4:\n",
    "            self.layer_norm = nn.LayerNorm(self.hidden_size, eps=1e-5)      # Normalization\n",
    "        if mod >= 2:\n",
    "            self.inter_proj = nn.Linear(self.hidden_size, self.inter_size)  # Intermediate dense layer\n",
    "        self.out_proj = nn.Linear(self.inter_size, 2)                       # Output layer\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        x = self.in_proj(embeddings)\n",
    "        x = self.dropout(x) if self.mod >= 5 else x\n",
    "        x = self.layer_norm(x) if self.mod >= 4 else x\n",
    "        x = self.silu(x) if self.mod >= 3 else x\n",
    "        x = x + self.in_proj(embeddings) if self.mod >= 6 else x\n",
    "        x = self.inter_proj(x) if self.mod >= 2 else x\n",
    "        x = self.dropout(x) if self.mod >= 5 else x\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdbac0-d3a1-4174-81b1-99db2cb01303",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10eddf-9e3f-4a8e-bd46-407b6a9d8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38fab5-37ce-4c17-9ecf-c8206990af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(batch, classifier, optimizer, metrics):\n",
    "    # Unpack the batch and move tensors to the device\n",
    "    embeddings, b_labels, b_ids = [t.to(device) for t in batch]\n",
    "    # Reset gradients before backpropagation\n",
    "    classifier.zero_grad()\n",
    "    # Perform a forward pass to calculate outputs using embeddings as input\n",
    "    logits = classifier(embeddings)\n",
    "    # Store results for later analysis\n",
    "    all_logits.append(logits.detach().cpu())\n",
    "    all_labels.append(b_labels.detach().cpu())\n",
    "    all_ids.append(b_ids.detach().cpu())\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(logits, b_labels)\n",
    "    metrics['batch_train_losses'].append(loss.item())\n",
    "    # Calculate accuracy\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = (preds == b_labels).sum().item() / b_labels.size(0)\n",
    "    metrics['batch_train_accuracy'].append(accuracy)\n",
    "    # Backpropagate the loss\n",
    "    loss.backward()\n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c327fe7-1a18-4306-880f-008205457ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(batch, classifier, optimizer, metrics):\n",
    "    # Unpack the batch and move tensors to the device\n",
    "    embeddings, b_labels, b_ids = [t.to(device) for t in batch]\n",
    "    # Forward pass using embeddings as input\n",
    "    logits = classifier(embeddings)\n",
    "    # Store results for later analysis\n",
    "    all_logits.append(logits.detach().cpu())\n",
    "    all_labels.append(b_labels.detach().cpu())\n",
    "    all_ids.append(b_ids.detach().cpu())\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(logits, b_labels)\n",
    "    metrics['batch_test_losses'].append(loss.item())\n",
    "    # Calculate accuracy\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = (preds == b_labels).sum().item() / b_labels.size(0)\n",
    "    metrics['batch_test_accuracy'].append(accuracy)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765304cb-3b1f-4c89-9acc-04062e29e79a",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6dc87-a7da-4ea3-867e-6fb0561c87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_metrics(metrics_dict, all_logits, dataloader_length, phase):\n",
    "    batch_loss_key = f'batch_{phase}_losses'\n",
    "    batch_acc_key = f'batch_{phase}_accuracy'\n",
    "    \n",
    "    # Loss and accuracy\n",
    "    avg_loss = np.mean(metrics_dict[batch_loss_key][-dataloader_length:])\n",
    "    metrics_dict[f'epoch_{phase}_loss'] = float(avg_loss)\n",
    "    avg_accuracy = np.mean(metrics_dict[batch_acc_key][-dataloader_length:])\n",
    "    metrics_dict[f'epoch_{phase}_accuracy'] = float(avg_accuracy)\n",
    "    \n",
    "    # Classification error\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    probs = F.softmax(all_logits, dim=1).detach()\n",
    "    prob_class_0 = probs[:, 0]\n",
    "    prob_class_1 = probs[:, 1]\n",
    "    classif_error = (1 - torch.max(prob_class_0, prob_class_1)).mean().item()\n",
    "    metrics_dict[f'{phase}_classif_error'] = float(classif_error)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d533b-87a9-4aa1-bf69-1ee6e5c1e6a1",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb5fa6-5ba5-4c85-b374-bdcfa6e4ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "print(f\"Number of training steps per model: {num_training_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13237b3a-9be8-4b3f-87d6-76e4b756c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_and_scheduler(classifier):\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        classifier.parameters(),\n",
    "        lr = 1e-3,\n",
    "        weight_decay = 0.01,\n",
    "        eps = 1e-8)\n",
    "\n",
    "    # Scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"cosine\",\n",
    "        optimizer = optimizer,\n",
    "        num_warmup_steps = 0.1 * num_training_steps,\n",
    "        num_training_steps = num_training_steps)\n",
    "\n",
    "    return optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea18571-6ad6-4035-a95c-3bb75e1b1b28",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb819a-8da0-4897-8c10-4b8fad804645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = {mod_type: {} for mod_type in range(1, 7)}\n",
    "\n",
    "manager = enlighten.get_manager()\n",
    "model_progress = manager.counter(total=6, desc=\"Models  ->\", unit=\"model\", color=\"forestgreen\")\n",
    "\n",
    "for mod_type in range(1, 7):\n",
    "    ### Create model\n",
    "    classifier = RoBERTaClassifier(embedding_dim=1024, mod=mod_type).to(device)\n",
    "    optimizer, lr_scheduler = get_optimizer_and_scheduler(classifier)\n",
    "    \n",
    "    metrics[mod_type] = {}\n",
    "    metrics[mod_type]['parameters'] = sum(p.numel() for p in classifier.parameters() if p.requires_grad)\n",
    "\n",
    "    # Loop over epochs\n",
    "    epoch_progress = manager.counter(total=num_epochs, desc=f\"Model {mod_type} ->\", unit=\"epoch\", color=\"darkgrey\")\n",
    "    for epoch in range(0, num_epochs):\n",
    "        metrics[mod_type][epoch] = {'batch_train_losses': [],\n",
    "                                    'batch_train_accuracy': [],\n",
    "                                    'batch_test_losses': [],\n",
    "                                    'batch_test_accuracy': []}\n",
    "\n",
    "        ### Training\n",
    "        classifier.train()\n",
    "        all_logits, all_labels, all_ids = [], [], []\n",
    "        for batch in train_dataloader:\n",
    "            loss = model_train(batch, classifier, optimizer, metrics[mod_type][epoch])\n",
    "        _ = get_epoch_metrics(metrics[mod_type][epoch], all_logits, len(train_dataloader), phase='train')\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        ### Validating\n",
    "        classifier.eval()\n",
    "        all_logits, all_labels, all_ids = [], [], []\n",
    "        for batch in test_dataloader:\n",
    "            loss = model_eval(batch, classifier, optimizer, metrics[mod_type][epoch])\n",
    "        probs = get_epoch_metrics(metrics[mod_type][epoch], all_logits, len(test_dataloader), phase='test')\n",
    "\n",
    "        ### Saving predictions\n",
    "        epoch_accuracy = metrics[mod_type][epoch]['epoch_test_accuracy']\n",
    "        best_test_accuracy = max(\n",
    "            metrics[mod_type][epoch]['epoch_test_accuracy']\n",
    "            for epoch in metrics[mod_type]\n",
    "            if epoch != 'parameters')\n",
    "        if epoch_accuracy >= best_test_accuracy:\n",
    "            probs_array = probs.cpu().numpy()\n",
    "            labels_array = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    "            results = pd.DataFrame(probs_array, columns=[f\"prob_class_{i}\" for i in range(probs_array.shape[1])])\n",
    "            results['true_label'] = [id2label[label] for label in labels_array]\n",
    "            results['review_id'] = torch.cat(all_ids, dim=0).detach().cpu().numpy()\n",
    "            results.to_csv(f\"output/preds/mod_{mod_type}_epoch_{epoch}.csv\", index=False)\n",
    "\n",
    "        epoch_progress.update()\n",
    "    model_progress.update()\n",
    "manager.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5f1cf-85fa-4dff-a636-3e5a962846a0",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfed8b1-945e-4aa6-88d1-6879d69f88a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the best epoch for each model\n",
    "summary = []\n",
    "\n",
    "for mod_type in metrics:\n",
    "    epoch_accuracies = [\n",
    "        (epoch, data['epoch_test_accuracy'])\n",
    "        for epoch, data in metrics[mod_type].items()\n",
    "        if isinstance(epoch, int) and 'epoch_test_accuracy' in data]\n",
    "\n",
    "    if epoch_accuracies:\n",
    "        best_epoch, best_accuracy = max(epoch_accuracies, key=lambda x: x[1])\n",
    "        best_error = metrics[mod_type][best_epoch]['test_classif_error']\n",
    "        summary.append({\n",
    "            'mod_type': mod_type,\n",
    "            'n_parameters': metrics[mod_type]['parameters'],\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_test_accuracy': best_accuracy,\n",
    "            'test_classif_error': best_error})\n",
    "\n",
    "summary = pd.DataFrame(summary).sort_values(by='mod_type')\n",
    "summary.style.hide(axis=\"index\").format({\n",
    "    \"best_test_accuracy\": \"{:.4f}\",\n",
    "    \"test_classif_error\": \"{:.4f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8dcd61-4481-4585-8b8c-c9a4e8d64f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the best model`\n",
    "best_model_index = summary['best_test_accuracy'].idxmax()\n",
    "best_model_info = summary.loc[best_model_index]\n",
    "\n",
    "best_mod_type = int(best_model_info['mod_type'])\n",
    "best_epoch = int(best_model_info['best_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c94a17-09f2-4d44-b651-5a10e6a3e27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for ploting performance curves\n",
    "## Convert results from dictionnary to df\n",
    "rows = []\n",
    "for mod_type, subdict in metrics.items():\n",
    "    for epoch_key, metric in subdict.items():\n",
    "        if epoch_key == 'parameters':\n",
    "            continue\n",
    "        if isinstance(metric, dict):\n",
    "            rows.append({\n",
    "                \"mod_type\": mod_type,\n",
    "                \"epoch\": epoch_key,\n",
    "                \"epoch_train_loss\": metric.get(\"epoch_train_loss\"),\n",
    "                \"epoch_test_loss\": metric.get(\"epoch_test_loss\"),\n",
    "                \"epoch_train_accuracy\": metric.get(\"epoch_train_accuracy\"),\n",
    "                \"epoch_test_accuracy\": metric.get(\"epoch_test_accuracy\"),\n",
    "                \"train_classif_errors\": metric.get(\"train_classif_error\"),\n",
    "                \"test_classif_errors\": metric.get(\"test_classif_error\")\n",
    "            })\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "## Extract values for best model\n",
    "df_subset = df[df[\"mod_type\"] == best_mod_type].sort_values(by=\"epoch\")\n",
    "epoch_train_losses = df_subset[\"epoch_train_loss\"].tolist()\n",
    "epoch_test_losses = df_subset[\"epoch_test_loss\"].tolist()\n",
    "epoch_train_accuracy = df_subset[\"epoch_train_accuracy\"].tolist()\n",
    "epoch_test_accuracy = df_subset[\"epoch_test_accuracy\"].tolist()\n",
    "train_classif_errors = df_subset[\"train_classif_errors\"].tolist()\n",
    "test_classif_errors = df_subset[\"test_classif_errors\"].tolist()\n",
    "\n",
    "## Identify min / max values (on the right part of the graph)\n",
    "epochs = np.linspace(21, 300, len(test_classif_errors))\n",
    "min_epoch_loss, min_loss = min(zip(epochs, epoch_test_losses), key=lambda x: x[1])\n",
    "max_epoch_acc, max_accuracy = max(zip(epochs, epoch_test_accuracy), key=lambda x: x[1])\n",
    "min_epoch_err, min_error = min(zip(epochs, test_classif_errors), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921d352-e668-402e-873a-d48c92df2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "gs = fig.add_gridspec(3, 2, width_ratios=[1, 3])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(epoch_train_losses, label='Train', color='#97BC62FF')\n",
    "ax1.plot(epoch_test_losses, label='Test', color='#2C5F2D', alpha=0.8)\n",
    "ax1.set_xticks(np.linspace(0, num_epochs, 6))\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(epoch_train_losses, color='#97BC62FF')\n",
    "ax2.plot(epoch_test_losses, color='#2C5F2D', alpha=0.8)\n",
    "ax2.axvline(min_epoch_loss, color='darkorchid', linestyle='--', alpha=0.6, label=f'≥ {min_loss:.4f}')\n",
    "ax2.set_xticks(np.arange(21, num_epochs+1, (num_epochs-21)//8))\n",
    "plt.xlim(21, num_epochs)\n",
    "plt.ylim(0.14, 0.33)\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax3.plot(epoch_train_accuracy, label='Train', color='#9CC3D5FF')\n",
    "ax3.plot(epoch_test_accuracy, label='Test', color='#0063B2FF')\n",
    "ax3.set_xticks(np.linspace(0, num_epochs, 6))\n",
    "ax3.set_xlabel('')\n",
    "ax3.set_ylabel('')\n",
    "ax3.set_title('Accuracy')\n",
    "ax3.legend()\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.plot(epoch_train_accuracy, color='#9CC3D5FF')\n",
    "ax4.plot(epoch_test_accuracy, color='#0063B2FF')\n",
    "ax4.axvline(max_epoch_acc, color='darkorchid', linestyle='--', alpha=0.6, label=f'≤ {max_accuracy:.4f}')\n",
    "ax4.set_xticks(np.arange(21, num_epochs+1, (num_epochs-21)//8))\n",
    "plt.xlim(21, num_epochs)\n",
    "plt.ylim(0.87, 0.95)\n",
    "ax4.set_xlabel('')\n",
    "ax4.set_ylabel('')\n",
    "ax4.set_title('Accuracy')\n",
    "ax4.legend()\n",
    "\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "ax5.plot(train_classif_errors, label='Train', color='#F5C7B8FF')\n",
    "ax5.plot(test_classif_errors, label='Test', color='#FFA177FF')\n",
    "ax5.set_xticks(np.linspace(0, num_epochs, 6))\n",
    "ax5.set_xlabel('Epochs')\n",
    "ax5.set_ylabel('')\n",
    "ax5.set_title('Classification Error')\n",
    "ax5.legend()\n",
    "\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax6.plot(train_classif_errors, color='#F5C7B8FF')\n",
    "ax6.plot(test_classif_errors, color='#FFA177FF')\n",
    "ax6.axvline(min_epoch_err, color='darkorchid', linestyle='--', alpha=0.6, label=f'≥ {min_error:.4f}')\n",
    "ax6.set_xticks(np.arange(21, num_epochs+1, (num_epochs-21)//8))\n",
    "plt.xlim(21, num_epochs)\n",
    "plt.ylim(0.058, 0.088)\n",
    "ax6.set_xlabel('Epochs')\n",
    "ax6.set_ylabel('')\n",
    "ax6.set_title('Classification Error')\n",
    "ax6.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output/mod_type_{mod_type}_learning_curves.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b750b-411b-4b93-a55a-00b614c39930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with original dataset\n",
    "test = pd.read_csv(\"data/processed/test.csv\")\n",
    "results = pd.read_csv(f\"output/preds/mod_{best_mod_type}_epoch_{best_epoch}.csv\")\n",
    "results = pd.merge(test, results, on = 'review_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19153c6-bfe6-495d-8335-00b65435f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for consistency\n",
    "print(f\"Do the true labels returned by the model match the original sentiments?\")\n",
    "print(f\"Yes!\" if (results['sentiment'] == results['true_label']).all() else f\"No :'(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1f232-ac68-4aa3-9841-0950efb8d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted sentiments and save\n",
    "results['RoBERTa_ft'] = np.where(results['prob_class_1'] >= 0.5, 'positive', 'negative')\n",
    "results[['review_id', 'RoBERTa_ft']].to_csv(\"output/RoBERTa_ft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dc9d7-f74b-4282-8058-89d2106eeab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
