{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08144275-905a-4829-836f-517d8294e17f",
   "metadata": {},
   "source": [
    "# Fine-tuning RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68687f9f-dfc5-45ba-9bbc-9758e4b6e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import get_scheduler, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2ecc8-6384-471b-964d-f1a536724bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): device = torch.device(\"mps\")\n",
    "else: device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551f14c-1c9a-422b-97fe-a915300b0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/embeddings/\", exist_ok=True)\n",
    "os.makedirs(\"output/preds/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283350c-522b-4206-b01e-40fb59ad359a",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To improve efficiency, perform a forward pass through the base model, and store the resulting embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21a646-a7df-4b8c-9796-958d61a9cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=250\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, tokenizer, base_model, label2id, batch_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.base_model = base_model.to(device)\n",
    "        self.base_model.eval()\n",
    "        self.label2id = label2id\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def extract_embeddings(self, texts):\n",
    "        \"\"\"Parallelized embedding extraction in batches with progress bar.\"\"\"\n",
    "        dataloader = DataLoader(texts, batch_size=self.batch_size, shuffle=False)\n",
    "        all_embeddings = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"Extracting Embeddings\", leave=True):\n",
    "                tokens = self.tokenizer(\n",
    "                    batch,\n",
    "                    padding=\"longest\",\n",
    "                    truncation=True,\n",
    "                    return_token_type_ids=False,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(device)\n",
    "\n",
    "                outputs = self.base_model(**tokens)\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "                all_embeddings.append(embeddings.cpu())          # Move to CPU to save memory\n",
    "\n",
    "        return torch.cat(all_embeddings, dim=0)  # Concatenate all batches\n",
    "\n",
    "    def prepare(self, data):\n",
    "        \"\"\"Prepare dataloader with precomputed embeddings.\"\"\"\n",
    "        texts = data[\"text\"].tolist()\n",
    "        embeddings = self.extract_embeddings(texts)\n",
    "\n",
    "        # Convert labels\n",
    "        numeric_labels = [self.label2id[label] for label in data[\"sentiment\"]]\n",
    "        labels = torch.tensor(numeric_labels, dtype=torch.long)\n",
    "\n",
    "        # Extract review IDs\n",
    "        ids = torch.tensor(data[\"review_id\"].tolist(), dtype=torch.long)\n",
    "\n",
    "        # Create dataset and dataloader\n",
    "        dataset = TensorDataset(embeddings, labels, ids)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585092f9-3d63-4b57-88f1-f7041bdf9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
    "base_model = RobertaModel.from_pretrained(\"roberta-large\")\n",
    "\n",
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "label2id = {\"negative\": 0, \"positive\": 1}\n",
    "\n",
    "preprocessor = DataPreprocessor(tokenizer, base_model, label2id, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de8060-2d92-4f29-8aca-01251f2c2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_savefile = \"data/embeddings/train.pt\"\n",
    "\n",
    "if os.path.exists(train_savefile):\n",
    "    print(f\"Loading embeddings for train samples\")\n",
    "    train_tensors = torch.load(train_savefile)\n",
    "    train_dataset = TensorDataset(*train_tensors)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    train = pd.read_csv(\"data/processed/train.csv\")\n",
    "    train_dataloader = preprocessor.prepare(train)\n",
    "    train_dataset = train_dataloader.dataset\n",
    "    torch.save(train_dataset.tensors, train_savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8679b1-19f2-4519-87af-bebd28a77825",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_savefile = \"data/embeddings/test.pt\"\n",
    "\n",
    "if os.path.exists(test_savefile):\n",
    "    print(f\"Loading embeddings for validation samples\")\n",
    "    test_tensors = torch.load(test_savefile)\n",
    "    test_dataset = TensorDataset(*test_tensors)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=250, shuffle=True)\n",
    "else:\n",
    "    test = pd.read_csv(\"data/processed/test.csv\")\n",
    "    test_dataloader = preprocessor.prepare(test)\n",
    "    test_dataset = test_dataloader.dataset\n",
    "    torch.save(test_dataset.tensors, test_savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026af54-5eb7-476f-a24b-71f797716049",
   "metadata": {},
   "source": [
    "# Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc7228-4195-481b-a2ef-cf77cb134a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaClassifier(nn.Module): \n",
    "    def __init__(self, embedding_dim=1024, mod=1): \n",
    "        super(RoBERTaClassifier, self).__init__()\n",
    "      ### Parameters\n",
    "        self.mod = mod\n",
    "        self.hidden_size = 1024 if mod==1 else 2048\n",
    "        self.inter_size = 1024 if mod==1 else 512\n",
    "      ### Layers\n",
    "      ### Must be activated in __init__ for the trainable parameters count to be exact\n",
    "        self.in_proj = nn.Linear(embedding_dim, self.hidden_size)           # Input layer\n",
    "        self.dropout = nn.Dropout(0.1)                                      # Dropout layer\n",
    "        self.silu = nn.SiLU()                                               # Activation\n",
    "        if mod >= 4:\n",
    "            self.layer_norm = nn.LayerNorm(self.hidden_size, eps=1e-5)      # Normalization\n",
    "        if mod >= 2:\n",
    "            self.inter_proj = nn.Linear(self.hidden_size, self.inter_size)  # Intermediate dense layer\n",
    "        self.out_proj = nn.Linear(self.inter_size, 2)                       # Output layer\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        x = self.in_proj(embeddings)\n",
    "        x = self.dropout(x) if self.mod>=5 else x\n",
    "        x = self.layer_norm(x) if self.mod>=4 else x\n",
    "        x = self.silu(x) if self.mod>=3 else x\n",
    "        x = x + self.in_proj(embeddings) if self.mod>=6 else x\n",
    "        x = self.inter_proj(x) if self.mod>=2 else x\n",
    "        x = self.dropout(x) if self.mod>=5 else x\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdbac0-d3a1-4174-81b1-99db2cb01303",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c327fe7-1a18-4306-880f-008205457ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def model_train(batch, classifier, optimizer, metrics):\n",
    "    # Unpack the batch and move tensors to the device\n",
    "    embeddings, b_labels, b_ids = [t.to(device) for t in batch]\n",
    "    # Reset gradients before backpropagation\n",
    "    classifier.zero_grad()\n",
    "    # Perform a forward pass to calculate outputs using embeddings as input\n",
    "    logits = classifier(embeddings)\n",
    "    # Store results for later analysis\n",
    "    all_logits.append(logits.detach().cpu())\n",
    "    all_labels.append(b_labels.detach().cpu())\n",
    "    all_ids.append(b_ids.detach().cpu())\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(logits, b_labels)\n",
    "    metrics['batch_train_losses'].append(loss.item())\n",
    "    # Calculate accuracy\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = (preds == b_labels).sum().item() / b_labels.size(0)\n",
    "    metrics['batch_train_accuracy'].append(accuracy)\n",
    "    # Backpropagate the loss\n",
    "    loss.backward()\n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def model_eval(batch, classifier, optimizer, metrics):\n",
    "    # Unpack the batch and move tensors to the device\n",
    "    embeddings, b_labels, b_ids = [t.to(device) for t in batch]\n",
    "    # Forward pass using embeddings as input\n",
    "    logits = classifier(embeddings)\n",
    "    # Store results for later analysis\n",
    "    all_logits.append(logits.detach().cpu())\n",
    "    all_labels.append(b_labels.detach().cpu())\n",
    "    all_ids.append(b_ids.detach().cpu())\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(logits, b_labels)\n",
    "    metrics['batch_test_losses'].append(loss.item())\n",
    "    # Calculate accuracy\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = (preds == b_labels).sum().item() / b_labels.size(0)\n",
    "    metrics['batch_test_accuracy'].append(accuracy)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d533b-87a9-4aa1-bf69-1ee6e5c1e6a1",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13237b3a-9be8-4b3f-87d6-76e4b756c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "print(f\"Number of training steps: {num_training_steps}\")\n",
    "\n",
    "def get_optimizer_and_scheduler(classifier):\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        classifier.parameters(),\n",
    "        lr = 1e-3,\n",
    "        weight_decay = 0.01,\n",
    "        eps = 1e-8)\n",
    "\n",
    "    # Scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"cosine\",\n",
    "        optimizer = optimizer,\n",
    "        num_warmup_steps = 0.1 * num_training_steps,\n",
    "        num_training_steps = num_training_steps)\n",
    "\n",
    "    return optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea18571-6ad6-4035-a95c-3bb75e1b1b28",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c502f64-4235-4158-afd6-2c3e4b251697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = {mod_type: {} for mod_type in range(1, 7)}\n",
    "\n",
    "model_progress = tqdm(range(1, 7), desc = \"Models\", position = 0, unit = \"model\")\n",
    "for mod_type in model_progress:\n",
    "    ### Create model\n",
    "    classifier = RoBERTaClassifier(embedding_dim=1024, mod=mod_type).to(device)\n",
    "    optimizer, lr_scheduler = get_optimizer_and_scheduler(classifier)\n",
    "    \n",
    "    metrics[mod_type] = {}\n",
    "    metrics[mod_type]['parameters'] = sum(p.numel() for p in classifier.parameters() if p.requires_grad)\n",
    "\n",
    "    # Loop over epochs\n",
    "    epoch_progress = tqdm(range(1, num_epochs), desc = f\"Model {mod_type}\", position = 1, unit = \"epoch\")\n",
    "    for epoch in epoch_progress:\n",
    "        metrics[mod_type][epoch] = {\n",
    "            'batch_train_losses': [],\n",
    "            'batch_train_accuracy': [],\n",
    "            'batch_test_losses': [],\n",
    "            'batch_test_accuracy': []}\n",
    "\n",
    "        ### Training\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        all_ids = []\n",
    "        \n",
    "        classifier.train()\n",
    "        for batch in train_dataloader:\n",
    "            loss = model_train(batch, classifier, optimizer, metrics[mod_type][epoch])\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # Loss & accuracy\n",
    "        avg_train_loss = np.mean(metrics[mod_type][epoch]['batch_train_losses'][-len(train_dataloader):])\n",
    "        metrics[mod_type][epoch]['epoch_train_loss'] = avg_train_loss\n",
    "        avg_train_accuracy = np.mean(metrics[mod_type][epoch]['batch_train_accuracy'][-len(train_dataloader):])\n",
    "        metrics[mod_type][epoch]['epoch_train_accuracy'] = avg_train_accuracy\n",
    "        # Classification error\n",
    "        all_logits = torch.cat(all_logits, dim=0)\n",
    "        probs = F.softmax(all_logits, dim=1).detach()\n",
    "        prob_class_0 = probs[:, 0]\n",
    "        prob_class_1 = probs[:, 1]\n",
    "        classif_error = (1 - torch.max(prob_class_0, prob_class_1)).mean().item()\n",
    "        metrics[mod_type][epoch]['train_classif_error'] = classif_error\n",
    "\n",
    "        ### Validating\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        all_ids = []\n",
    "    \n",
    "        classifier.eval()\n",
    "        for batch in test_dataloader:\n",
    "            loss = model_eval(batch, classifier, optimizer, metrics[mod_type][epoch])\n",
    "\n",
    "        # Loss & accuracy\n",
    "        avg_test_loss = np.mean(metrics[mod_type][epoch]['batch_test_losses'][-len(test_dataloader):])\n",
    "        metrics[mod_type][epoch]['epoch_test_loss'] = avg_test_loss\n",
    "        avg_test_accuracy = np.mean(metrics[mod_type][epoch]['batch_test_accuracy'][-len(test_dataloader):])\n",
    "        metrics[mod_type][epoch]['epoch_test_accuracy'] = avg_test_accuracy\n",
    "        # Classification error\n",
    "        all_logits = torch.cat(all_logits, dim=0)\n",
    "        probs = F.softmax(all_logits, dim=1).detach()\n",
    "        prob_class_0 = probs[:, 0]\n",
    "        prob_class_1 = probs[:, 1]\n",
    "        classif_error = (1 - torch.max(prob_class_0, prob_class_1)).mean().item()\n",
    "        metrics[mod_type][epoch]['test_classif_error'] = classif_error\n",
    "\n",
    "        ### Saving predictions\n",
    "        best_test_accuracy = max(\n",
    "            metrics[mod_type][epoch]['epoch_test_accuracy']\n",
    "            for epoch in metrics[mod_type]\n",
    "            if epoch != 'parameters')\n",
    "        if avg_test_accuracy >= best_test_accuracy:\n",
    "            probs_array = probs.cpu().numpy()\n",
    "            labels_array = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    "            results = pd.DataFrame(probs_array, columns=[f\"prob_class_{i}\" for i in range(probs_array.shape[1])])\n",
    "            results['true_label'] = [id2label[label] for label in labels_array]\n",
    "            results['review_id'] = torch.cat(all_ids, dim=0).detach().cpu().numpy()\n",
    "            results.to_csv(f\"output/preds/mod_{mod_type}_epoch_{epoch}.csv\", index=False)\n",
    "    \n",
    "        epoch_progress.set_postfix(acc=f\"{avg_test_accuracy:.4f}\",\n",
    "                                   best_acc=f\"{best_test_accuracy:.4f}\", \n",
    "                                   losses_ratio=f\"{avg_train_loss/avg_test_loss:.4f}\")\n",
    "\n",
    "    epoch_progress.close()\n",
    "model_progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5f1cf-85fa-4dff-a636-3e5a962846a0",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfed8b1-945e-4aa6-88d1-6879d69f88a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "\n",
    "for mod_type in metrics:\n",
    "    epoch_accuracies = [\n",
    "        (epoch, data['epoch_test_accuracy'])\n",
    "        for epoch, data in metrics[mod_type].items()\n",
    "        if isinstance(epoch, int) and 'epoch_test_accuracy' in data\n",
    "    ]\n",
    "\n",
    "    if epoch_accuracies:\n",
    "        best_epoch, best_accuracy = max(epoch_accuracies, key=lambda x: x[1])\n",
    "        best_error = metrics[mod_type][best_epoch]['test_classif_error']\n",
    "\n",
    "        summary.append({\n",
    "            'mod_type': mod_type,\n",
    "            'n_parameters': metrics[mod_type]['parameters'],\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_test_accuracy': best_accuracy,\n",
    "            'test_classif_error': best_error\n",
    "        })\n",
    "\n",
    "summary = pd.DataFrame(summary).sort_values(by='mod_type')\n",
    "summary.style.hide(axis=\"index\").format({\n",
    "    \"best_test_accuracy\": \"{:.4f}\",\n",
    "    \"test_classif_error\": \"{:.4f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8dcd61-4481-4585-8b8c-c9a4e8d64f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = summary['best_test_accuracy'].idxmax()\n",
    "best_model_info = summary.loc[best_model_index]\n",
    "\n",
    "best_mod_type = int(best_model_info['mod_type'])\n",
    "best_epoch = int(best_model_info['best_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c94a17-09f2-4d44-b651-5a10e6a3e27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for mod_type, subdict in metrics.items():\n",
    "    for epoch_key, metric in subdict.items():\n",
    "        if epoch_key == 'parameters':\n",
    "            continue\n",
    "        if isinstance(metric, dict):\n",
    "            rows.append({\n",
    "                \"mod_type\": mod_type,\n",
    "                \"epoch\": epoch_key,\n",
    "                \"epoch_train_loss\": metric.get(\"epoch_train_loss\"),\n",
    "                \"epoch_test_loss\": metric.get(\"epoch_test_loss\"),\n",
    "                \"epoch_train_accuracy\": metric.get(\"epoch_train_accuracy\"),\n",
    "                \"epoch_test_accuracy\": metric.get(\"epoch_test_accuracy\"),\n",
    "                \"train_classif_errors\": metric.get(\"train_classif_error\"),\n",
    "                \"test_classif_errors\": metric.get(\"test_classif_error\")\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd893a-1837-409f-a3b0-3d4bff173067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[df[\"mod_type\"] == best_mod_type].sort_values(by=\"epoch\")\n",
    "\n",
    "epoch_train_losses = df_subset[\"epoch_train_loss\"].tolist()\n",
    "epoch_test_losses = df_subset[\"epoch_test_loss\"].tolist()\n",
    "epoch_train_accuracy = df_subset[\"epoch_train_accuracy\"].tolist()\n",
    "epoch_test_accuracy = df_subset[\"epoch_test_accuracy\"].tolist()\n",
    "train_classif_errors = df_subset[\"train_classif_errors\"].tolist()\n",
    "test_classif_errors = df_subset[\"test_classif_errors\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbd3fd-224d-4f54-bb28-1162487cc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(np.arange(1, len(epoch_train_losses) + 1), epoch_train_losses, label='Train', color='#97BC62FF')\n",
    "plt.plot(np.arange(1, len(epoch_test_losses) + 1), epoch_test_losses, label='Test', color='#2C5F2D', alpha=0.8)\n",
    "plt.xticks(np.arange(0, len(epoch_train_losses) + 2, max(1, len(epoch_train_losses)//10)))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(np.arange(1, len(epoch_train_accuracy) + 1), epoch_train_accuracy, label='Train', color='#9CC3D5FF')\n",
    "plt.plot(np.arange(1, len(epoch_test_accuracy) + 1), epoch_test_accuracy, label='Test', color='#0063B2FF')\n",
    "plt.xticks(np.arange(0, len(epoch_test_accuracy) + 2, max(1, len(epoch_test_accuracy)//10)))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Classification Error\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(np.arange(1, len(train_classif_errors) + 1), train_classif_errors, label='Train', color='#F5C7B8FF')\n",
    "plt.plot(np.arange(1, len(test_classif_errors) + 1), test_classif_errors, label='Test', color='#FFA177FF')\n",
    "plt.xticks(np.arange(0, len(test_classif_errors) + 2, max(1, len(test_classif_errors)//10)))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('')\n",
    "plt.title('Classification Error')\n",
    "plt.legend()\n",
    "\n",
    "# Final Layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output/mod_type_{mod_type}_learning_curves.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c50cb4-0bd8-4df0-9a52-8c0a18ad99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.arange(1, len(epoch_train_losses) + 1), epoch_train_losses, label='Train', color='#97BC62FF')\n",
    "plt.plot(np.arange(1, len(epoch_test_losses) + 1), epoch_test_losses, label='Test', color='#2C5F2D', alpha=0.8)\n",
    "plt.xticks(np.arange(0, len(epoch_train_losses) + 2, max(1, len(epoch_train_losses)//10)))\n",
    "plt.xlim(21, 251)\n",
    "plt.ylim(0.15, 0.265)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(np.arange(1, len(epoch_train_accuracy) + 1), epoch_train_accuracy, label='Train', color='#9CC3D5FF')\n",
    "plt.plot(np.arange(1, len(epoch_test_accuracy) + 1), epoch_test_accuracy, label='Test', color='#0063B2FF')\n",
    "plt.xticks(np.arange(0, len(epoch_test_accuracy) + 2, max(1, len(epoch_test_accuracy)//10)))\n",
    "plt.xlim(21, 251)\n",
    "plt.ylim(0.9, 0.945)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Classification Error\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(np.arange(1, len(train_classif_errors) + 1), train_classif_errors, label='Train', color='#F5C7B8FF')\n",
    "plt.plot(np.arange(1, len(test_classif_errors) + 1), test_classif_errors, label='Test', color='#FFA177FF')\n",
    "plt.xticks(np.arange(0, len(test_classif_errors) + 2, max(1, len(test_classif_errors)//10)))\n",
    "plt.xlim(21, 251)\n",
    "plt.ylim(0.055, 0.09)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('')\n",
    "plt.title('Classification Error')\n",
    "plt.legend()\n",
    "\n",
    "# Final Layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output/mod_type_{mod_type}_learning_curves_zoom.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b750b-411b-4b93-a55a-00b614c39930",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/processed/test.csv\")\n",
    "results = pd.read_csv(f\"output/preds/mod_{best_mod_type}_epoch_{best_epoch}.csv\")\n",
    "results = pd.merge(test, results, on = 'review_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19153c6-bfe6-495d-8335-00b65435f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for consistency\n",
    "print(f\"Do the true labels returned by the model match the original sentiments?\")\n",
    "print(f\"Yes!\" if (results['sentiment'] == results['true_label']).all() else f\"No :'(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1f232-ac68-4aa3-9841-0950efb8d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted sentiments and save\n",
    "results['RoBERTa_ft'] = np.where(results['prob_class_1'] >= 0.5, 'positive', 'negative')\n",
    "results[['review_id', 'RoBERTa_ft']].to_csv(\"output/RoBERTa_ft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dc9d7-f74b-4282-8058-89d2106eeab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
