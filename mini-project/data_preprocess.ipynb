{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a92000-7b82-44c0-8376-1ce30b67c9ba",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68687f9f-dfc5-45ba-9bbc-9758e4b6e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea72103-73ff-4fa6-aec7-ba4c630b1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/processed/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39025866-c7e2-42e0-a78e-026e977f62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/processed/train.csv\")\n",
    "test = pd.read_csv(\"data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc907150-1f74-48b4-9c15-25df4e876eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id column as movie_id to avoid confusion\n",
    "train = train.rename(columns={'id': 'movie_id'})\n",
    "test = test.rename(columns={'id': 'movie_id'})\n",
    "\n",
    "# Create reviews id for matching with the original dataset\n",
    "train['review_id'] = train.index + 1\n",
    "test['review_id'] = test.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07cc36-46c7-4149-96c9-0c04b99556a6",
   "metadata": {},
   "source": [
    "## HTML markups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e82e06-9c50-4b27-a0de-a6e3383b64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_html_tags(text):\n",
    "    pattern = re.compile(r'<[^>]+>')\n",
    "    return bool(pattern.search(str(text)))\n",
    "\n",
    "train['has_html'] = train['text'].apply(contains_html_tags)\n",
    "test['has_html'] = test['text'].apply(contains_html_tags)\n",
    "\n",
    "train_html_count = train['has_html'].sum()\n",
    "train_total_count = len(train)\n",
    "train_percentage = (train_html_count / train_total_count) * 100\n",
    "\n",
    "test_html_count = test['has_html'].sum()\n",
    "test_total_count = len(test)\n",
    "test_percentage = (test_html_count / test_total_count) * 100\n",
    "\n",
    "print(f\"Reviews containing HTML markup in train: {train_html_count} out of {train_total_count} ({train_percentage:.2f}%)\")\n",
    "print(f\"Reviews containing HTML markup in test: {test_html_count} out of {train_total_count} ({test_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e6f1c-6050-48ff-86cf-2aff47f6610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html_tags(text):\n",
    "    pattern = re.compile(r'<([a-zA-Z][a-zA-Z0-9]*)')\n",
    "    matches = pattern.findall(str(text))\n",
    "    return matches\n",
    "\n",
    "if train_html_count + test_html_count > 0:\n",
    "    all_tags = []\n",
    "    for text in train[train['has_html']]['text']:\n",
    "        tags = extract_html_tags(text)\n",
    "        all_tags.extend(tags)\n",
    "\n",
    "    for text in test[test['has_html']]['text']:\n",
    "        tags = extract_html_tags(text)\n",
    "        all_tags.extend(tags)\n",
    "    \n",
    "    tag_counts = Counter(all_tags)\n",
    "    \n",
    "    print(\"\\nMost common HTML tags:\")\n",
    "    for tag, count in tag_counts.most_common(10):\n",
    "        print(f\"{tag} ({count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5e15a-adc3-447d-9652-2b861494f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_markups(text):\n",
    "    # Replace <SPOILER> tags with SPOILER\n",
    "    text = re.sub(r'<SPOILER>', 'SPOILER', str(text))\n",
    "    text = re.sub(r'</SPOILER>', 'SPOILER', str(text))\n",
    "    \n",
    "    # Replace <br> tags with line breaks\n",
    "    text = re.sub(r'<br\\s*/?>', '\\n', text)\n",
    "    \n",
    "    # Remove all other HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "train['text'] = train['text'].apply(remove_html_markups)\n",
    "test['text'] = test['text'].apply(remove_html_markups)\n",
    "\n",
    "train = train.drop(columns=['has_html'])\n",
    "test = test.drop(columns=['has_html'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa913a6-bdcf-4445-b777-8299fc8b867a",
   "metadata": {},
   "source": [
    "## Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f3c89-88f7-4a19-9819-66b3dd631881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples with emojis\n",
    "train['has_emoji'] = train['text'].apply(lambda x: emoji.emoji_count(x) > 0)\n",
    "train_emoji_count = train['has_emoji'].sum()\n",
    "train_total = len(train)\n",
    "train_percentage = (train_emoji_count / train_total) * 100\n",
    "\n",
    "test['has_emoji'] = test['text'].apply(lambda x: emoji.emoji_count(x) > 0)\n",
    "test_emoji_count = test['has_emoji'].sum()\n",
    "test_total = len(test)\n",
    "test_percentage = (test_emoji_count / test_total) * 100\n",
    "\n",
    "print(f\"Train set: {train_emoji_count} out of {train_total} samples contain emojis ({train_percentage:.2f}%)\")\n",
    "print(f\"Test set: {test_emoji_count} out of {test_total} samples contain emojis ({test_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd23a4-38f5-4d63-b5b6-3031c6387e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common emojis\n",
    "def extract_emojis(text):\n",
    "    return ''.join(c for c in text if c in emoji.EMOJI_DATA)\n",
    "\n",
    "all_train_emojis = ''.join(train['text'].apply(extract_emojis))\n",
    "train_emoji_counts = Counter(all_train_emojis)\n",
    "\n",
    "all_test_emojis = ''.join(test['text'].apply(extract_emojis))\n",
    "test_emoji_counts = Counter(all_test_emojis)\n",
    "\n",
    "print(\"\\nMost common emojis in train set:\")\n",
    "for em, count in train_emoji_counts.most_common(10):\n",
    "    print(f\"{em} ({count})\")\n",
    "\n",
    "print(\"\\nMost common emojis in test set:\")\n",
    "for em, count in test_emoji_counts.most_common(10):\n",
    "    print(f\"{em} ({count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222012d0-5fc1-436b-8a50-c74158b2430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    text = re.sub(r'[®©]', '', str(text))\n",
    "    \n",
    "    return text\n",
    "\n",
    "train['text'] = train['text'].apply(remove_emojis)\n",
    "test['text'] = test['text'].apply(remove_emojis)\n",
    "\n",
    "train = train.drop(columns=['has_emoji'])\n",
    "test = test.drop(columns=['has_emoji'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c609b8e-05da-405d-a09b-502e93117267",
   "metadata": {},
   "source": [
    "## Special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1127b52-dd2b-41ef-9f5c-8da8f7cb03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_special_chars(text):\n",
    "    # Define a pattern that matches special characters/accented letters\n",
    "    # but excludes common punctuation and standard ASCII letters/numbers\n",
    "    pattern = re.compile(r'[^\\x00-\\x7F]+')  # Matches any non-ASCII character\n",
    "    \n",
    "    return bool(pattern.search(str(text)))\n",
    "\n",
    "train['has_special_chars'] = train['text'].apply(has_special_chars)\n",
    "test['has_special_chars'] = test['text'].apply(has_special_chars)\n",
    "\n",
    "special_chars_count_train = train['has_special_chars'].sum()\n",
    "percentage = (special_chars_count_train / len(train)) * 100\n",
    "print(f\"Texts containing special characters: {special_chars_count_train} out of len(train) ({percentage:.2f}%)\")\n",
    "\n",
    "special_chars_count_test = test['has_special_chars'].sum()\n",
    "percentage = (special_chars_count_test / len(test)) * 100\n",
    "print(f\"Texts containing special characters: {special_chars_count_test} out of len(test) ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05849a3-9474-44ab-b752-07eff823ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars_train = ' '.join(train['text'][train['has_special_chars']].tolist())\n",
    "special_chars_test = ' '.join(test['text'][test['has_special_chars']].tolist())\n",
    "\n",
    "all_special_chars = re.findall(r'[^\\x00-\\x7F]', special_chars_train + special_chars_test)\n",
    "special_char_counts = Counter(all_special_chars)\n",
    "\n",
    "print(\"\\nMost frequent special characters:\")\n",
    "special_char_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68d30c-bc30-4be9-81ff-86ba0d23d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    '\\x96': '–',\n",
    "    '\\x97': '–',\n",
    "    '\\xad': '–',\n",
    "    '\\x85': '...',\n",
    "    '\\x91': '‘',\n",
    "    '\\u201c': '“',\n",
    "    '\\x93': '“',\n",
    "    '\\xa0': '',  # erase\n",
    "    '\\x8d': '',  # erase\n",
    "    '\\x9d': '',  # erase\n",
    "    '\\uf0b7': '',  # erase\n",
    "    '\\x81': '',  # erase\n",
    "    '\\x84': '”',\n",
    "    '\\x8e': 'Ž',\n",
    "    '\\x9e': 'ž',\n",
    "    '\\x9a': 'š',\n",
    "    '\\x95': '.',\n",
    "    '\\x80': '€',\n",
    "    '\\x99': '',  # TM\n",
    "    '\\x98': '~',\n",
    "    '\\x9c': 'œ',\n",
    "    '\\x9f': 'Ÿ',\n",
    "    '\\x82': ',',\n",
    "}\n",
    "\n",
    "def replace_special_chars(text):\n",
    "    for old_char, new_char in replacements.items():\n",
    "        text = text.replace(old_char, new_char)\n",
    "    return text\n",
    "\n",
    "train['text'] = train['text'].apply(replace_special_chars)\n",
    "test['text'] = test['text'].apply(replace_special_chars)\n",
    "\n",
    "train = train.drop(columns=['has_special_chars'])\n",
    "test = test.drop(columns=['has_special_chars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35061b4-5804-425d-b98f-b2cd9bc4af46",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56cb6e6-5a0e-4f2c-b050-b3a354134db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/processed/train.csv\", index=False)\n",
    "test.to_csv(\"data/processed/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
